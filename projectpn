import os
import telebot
import collections
import re
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
from itertools import chain
import string

API_KEY ='6806369048:AAFGcsXTHUPNqgXoDoaSDnXfDW-WOYdFSFg'
bot = telebot.TeleBot(API_KEY)

word_counts_dict = {}

@bot.message_handler(content_types=['text'])
def keys(message):
    if message.forward_date:
        text = message.text
        text = text.translate(str.maketrans('', '', string.punctuation)).lower()
        words = word_tokenize(text)
        lemmatizer = WordNetLemmatizer()
        stop_words = set(stopwords.words('english')).union(set(stopwords.words('russian')))
        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
        word_counts_dict[message.message_id] = collections.Counter(words)
        total_word_counts = collections.Counter()
        # Use enumerate(word_counts_dict.values(), 1) to start the count from 1
        for i, word_counts in enumerate(word_counts_dict.values(), 1):
            total_word_counts.update(word_counts)
        filtered_words = [word for word, count in total_word_counts.items() if count > 1]
        most_common_words = total_word_counts.most_common(7)
        most_common_words_string = '\n'.join([f'{word}: {count}' for word, count in most_common_words])
        if not len(filtered_words) :
            bot.reply_to(message, f'обо всём и ни о чём')
        else:
            bot.reply_to(message, f'\n{most_common_words_string}') 

bot.infinity_polling()
